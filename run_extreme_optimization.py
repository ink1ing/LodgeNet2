#!/usr/bin/env python
# -*- coding: utf-8 -*-
# æ—§ç‰ˆæœ¬æ–‡ä»¶ï¼šæç«¯ä¼˜åŒ–ç‰ˆè®­ç»ƒå¯åŠ¨è„šæœ¬ï¼Œå°è¯•æœ€å¤§åŒ–æ€§èƒ½
# LodgeNetæé™æ€§èƒ½ä¼˜åŒ–è„šæœ¬ï¼šæ¦¨å¹²RTX6000 22.5GB GPUçš„æ¯ä¸€åˆ†æ€§èƒ½
# ç›®æ ‡ï¼šè¾¾åˆ°80%ä»¥ä¸ŠGPUå†…å­˜ä½¿ç”¨ç‡ï¼Œæœ€å¤§åŒ–è®­ç»ƒé€Ÿåº¦å’Œç²¾åº¦

import os
import sys
import subprocess
import argparse
import torch
import psutil
from datetime import datetime
import json
import time

def extreme_performance_config():
    """
    æé™æ€§èƒ½é…ç½®ï¼šæœ€å¤§åŒ–åˆ©ç”¨RTX6000èµ„æº
    """
    print("=" * 80)
    print("ğŸš€ RTX6000 æé™æ€§èƒ½é…ç½®")
    print("=" * 80)
    
    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯ï¼šæœªæ£€æµ‹åˆ°CUDA GPU")
        return None
    
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    
    print(f"ğŸ¯ ç›®æ ‡GPU: {gpu_name}")
    print(f"ğŸ¯ GPUå†…å­˜: {gpu_memory:.1f} GB")
    
    # RTX6000ä¸“ç”¨æé™é…ç½®
    if "RTX 6000" in gpu_name or "Quadro RTX 6000" in gpu_name:
        extreme_config = {
            'batch_size': 512,      # æå¤§æ‰¹æ¬¡å¤§å°
            'img_size': 384,        # é«˜åˆ†è¾¨ç‡å›¾åƒ
            'num_workers': 20,      # æœ€å¤§å·¥ä½œè¿›ç¨‹
            'learning_rate': 0.002, # æ›´é«˜å­¦ä¹ ç‡é…åˆå¤§æ‰¹æ¬¡
            'target_memory_usage': 0.90,  # ç›®æ ‡90%å†…å­˜ä½¿ç”¨
            'gradient_accumulation': 2,    # æ¢¯åº¦ç´¯ç§¯
        }
        print("ğŸ”¥ å¯ç”¨RTX6000æé™é…ç½®")
    else:
        # é€šç”¨é«˜æ€§èƒ½é…ç½®
        extreme_config = {
            'batch_size': 256,
            'img_size': 256,
            'num_workers': 16,
            'learning_rate': 0.001,
            'target_memory_usage': 0.85,
            'gradient_accumulation': 1,
        }
        print("âš¡ å¯ç”¨é€šç”¨é«˜æ€§èƒ½é…ç½®")
    
    # ç³»ç»Ÿèµ„æºæ£€æŸ¥
    memory = psutil.virtual_memory()
    cpu_count = psutil.cpu_count()
    
    print(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜: {memory.total / 1024**3:.1f} GB")
    print(f"ğŸ–¥ï¸  CPUæ ¸å¿ƒ: {cpu_count}")
    print(f"âš™ï¸  æ¨èé…ç½®:")
    print(f"   - æ‰¹æ¬¡å¤§å°: {extreme_config['batch_size']}")
    print(f"   - å›¾åƒå°ºå¯¸: {extreme_config['img_size']}")
    print(f"   - å·¥ä½œè¿›ç¨‹: {extreme_config['num_workers']}")
    print(f"   - å­¦ä¹ ç‡: {extreme_config['learning_rate']}")
    print(f"   - ç›®æ ‡å†…å­˜ä½¿ç”¨: {extreme_config['target_memory_usage']:.0%}")
    
    return extreme_config

def stress_test_gpu(config):
    """
    GPUå‹åŠ›æµ‹è¯•ï¼šç¡®ä¿é…ç½®å¯è¡Œ
    """
    print(f"\nğŸ§ª GPUå‹åŠ›æµ‹è¯•...")
    
    try:
        from lodgenet_model import get_lodgenet_model
        
        device = torch.device('cuda')
        model = get_lodgenet_model(
            n_channels=3, 
            n_classes=2, 
            img_size=config['img_size']
        ).to(device)
        
        # å¯ç”¨æ··åˆç²¾åº¦
        scaler = torch.cuda.amp.GradScaler()
        optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'])
        
        # æµ‹è¯•æœ€å¤§æ‰¹æ¬¡å¤§å°
        max_batch_size = config['batch_size']
        test_passed = False
        
        for test_batch in [max_batch_size, max_batch_size//2, max_batch_size//4]:
            try:
                torch.cuda.empty_cache()
                
                # åˆ›å»ºæµ‹è¯•æ•°æ®
                test_input = torch.randn(test_batch, 3, config['img_size'], config['img_size']).to(device)
                test_pos_labels = torch.randint(0, 3, (test_batch,)).to(device)
                test_grade_labels = torch.rand(test_batch, 1).to(device) * 9
                
                # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
                model.train()
                optimizer.zero_grad()
                
                with torch.cuda.amp.autocast():
                    seg_out, pos_out, grade_out = model(test_input)
                    
                    # ç®€å•æŸå¤±è®¡ç®—
                    pos_loss = torch.nn.functional.cross_entropy(pos_out, test_pos_labels)
                    grade_loss = torch.nn.functional.mse_loss(grade_out, test_grade_labels)
                    total_loss = pos_loss + grade_loss
                
                scaler.scale(total_loss).backward()
                scaler.step(optimizer)
                scaler.update()
                
                # æ£€æŸ¥å†…å­˜ä½¿ç”¨
                memory_used = torch.cuda.memory_allocated(0) / torch.cuda.get_device_properties(0).total_memory
                memory_cached = torch.cuda.memory_reserved(0) / torch.cuda.get_device_properties(0).total_memory
                
                print(f"âœ… æ‰¹æ¬¡å¤§å° {test_batch}: å†…å­˜ä½¿ç”¨ {memory_used:.1%}, ç¼“å­˜ {memory_cached:.1%}")
                
                if memory_used < config['target_memory_usage']:
                    config['batch_size'] = test_batch
                    test_passed = True
                    break
                else:
                    print(f"âš ï¸  æ‰¹æ¬¡å¤§å° {test_batch}: å†…å­˜ä½¿ç”¨è¿‡é«˜ ({memory_used:.1%})")
                    
            except RuntimeError as e:
                if "out of memory" in str(e):
                    print(f"âŒ æ‰¹æ¬¡å¤§å° {test_batch}: GPUå†…å­˜ä¸è¶³")
                    torch.cuda.empty_cache()
                    continue
                else:
                    raise e
        
        del model, optimizer, scaler
        torch.cuda.empty_cache()
        
        if test_passed:
            print(f"ğŸ‰ å‹åŠ›æµ‹è¯•é€šè¿‡ï¼æœ€ç»ˆæ‰¹æ¬¡å¤§å°: {config['batch_size']}")
            return True
        else:
            print(f"âŒ å‹åŠ›æµ‹è¯•å¤±è´¥ï¼Œé™çº§åˆ°å®‰å…¨é…ç½®")
            config['batch_size'] = 32
            config['img_size'] = 128
            return False
            
    except Exception as e:
        print(f"âŒ å‹åŠ›æµ‹è¯•å‡ºé”™: {e}")
        return False

def create_extreme_training_command(config, args):
    """
    åˆ›å»ºæé™æ€§èƒ½è®­ç»ƒå‘½ä»¤
    """
    cmd = [
        sys.executable, 'lodgenet_train.py',
        '--data_root', args.data_root,
        '--json_root', args.json_root,
        '--batch_size', str(config['batch_size']),
        '--num_epochs', str(args.num_epochs),
        '--learning_rate', str(config['learning_rate']),
        '--num_workers', str(config['num_workers']),
        '--img_size', str(config['img_size']),
        '--output_dir', args.output_dir
    ]
    
    return cmd

def monitor_extreme_performance(log_file):
    """
    æé™æ€§èƒ½ç›‘æ§
    """
    def performance_monitor():
        max_gpu_memory = 0
        max_gpu_utilization = 0
        
        while True:
            try:
                if torch.cuda.is_available():
                    gpu_memory_used = torch.cuda.memory_allocated(0) / 1024**3
                    gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
                    gpu_memory_percent = gpu_memory_used / gpu_memory_total * 100
                    
                    max_gpu_memory = max(max_gpu_memory, gpu_memory_percent)
                    
                    # GPUåˆ©ç”¨ç‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    try:
                        import nvidia_ml_py3 as nvml
                        nvml.nvmlInit()
                        handle = nvml.nvmlDeviceGetHandleByIndex(0)
                        utilization = nvml.nvmlDeviceGetUtilizationRates(handle)
                        gpu_util = utilization.gpu
                        max_gpu_utilization = max(max_gpu_utilization, gpu_util)
                    except:
                        gpu_util = 0
                else:
                    gpu_memory_percent = 0
                    gpu_util = 0
                
                # CPUå’Œå†…å­˜
                cpu_percent = psutil.cpu_percent()
                memory = psutil.virtual_memory()
                
                # è®°å½•æ€§èƒ½æ•°æ®
                timestamp = datetime.now().strftime("%H:%M:%S")
                perf_info = (f"[{timestamp}] ğŸš€ GPU: {gpu_memory_percent:.1f}% "
                           f"({gpu_memory_used:.1f}GB), GPUåˆ©ç”¨ç‡: {gpu_util}%, "
                           f"CPU: {cpu_percent:.1f}%, RAM: {memory.percent:.1f}%")
                
                print(f"\r{perf_info}", end='', flush=True)
                
                with open(log_file.replace('.log', '_extreme_perf.log'), 'a', encoding='utf-8') as f:
                    f.write(perf_info + '\n')
                
                # æ¯10ç§’æ›´æ–°ä¸€æ¬¡
                time.sleep(10)
                
            except Exception:
                break
    
    import threading
    monitor_thread = threading.Thread(target=performance_monitor, daemon=True)
    monitor_thread.start()

def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description='LodgeNetæé™æ€§èƒ½ä¼˜åŒ–è®­ç»ƒ')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--data_root', type=str, default='./guanceng-bit',
                        help='TIFå›¾åƒæ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--json_root', type=str, default='./biaozhu_json',
                        help='JSONæ ‡æ³¨æ•°æ®æ ¹ç›®å½•')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--num_epochs', type=int, default=50,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--output_dir', type=str, default=None,
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--log_dir', type=str, default='./logs',
                        help='æ—¥å¿—ç›®å½•')
    
    # æé™ä¼˜åŒ–é€‰é¡¹
    parser.add_argument('--skip_stress_test', action='store_true',
                        help='è·³è¿‡GPUå‹åŠ›æµ‹è¯•')
    
    args = parser.parse_args()
    
    print("ğŸ”¥" * 40)
    print("ğŸš€ LodgeNet æé™æ€§èƒ½ä¼˜åŒ–è®­ç»ƒ")
    print("ğŸ¯ ç›®æ ‡ï¼šæ¦¨å¹²RTX6000çš„æ¯ä¸€åˆ†æ€§èƒ½")
    print("ğŸ”¥" * 40)
    
    # è·å–æé™é…ç½®
    config = extreme_performance_config()
    if config is None:
        return 1
    
    # GPUå‹åŠ›æµ‹è¯•
    if not args.skip_stress_test:
        if not stress_test_gpu(config):
            print("âš ï¸  ä½¿ç”¨é™çº§é…ç½®ç»§ç»­è®­ç»ƒ")
    
    # ç”Ÿæˆæ—¶é—´æˆ³å’Œç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    if args.output_dir is None:
        args.output_dir = f'./output_lodgenet_extreme_{timestamp}'
    
    os.makedirs(args.output_dir, exist_ok=True)
    log_file = os.path.join(args.log_dir, f'lodgenet_extreme_{timestamp}.log')
    
    # åˆ›å»ºè®­ç»ƒå‘½ä»¤
    cmd = create_extreme_training_command(config, args)
    
    print(f"\nğŸš€ æé™è®­ç»ƒé…ç½®:")
    print(f"   ğŸ“Š æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
    print(f"   ğŸ–¼ï¸  å›¾åƒå°ºå¯¸: {config['img_size']}x{config['img_size']}")
    print(f"   âš¡ å·¥ä½œè¿›ç¨‹: {config['num_workers']}")
    print(f"   ğŸ“ˆ å­¦ä¹ ç‡: {config['learning_rate']}")
    print(f"   ğŸ’¾ ç›®æ ‡å†…å­˜ä½¿ç”¨: {config['target_memory_usage']:.0%}")
    print(f"   ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"   ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    # é¢„ä¼°æ€§èƒ½
    estimated_memory = config['batch_size'] * config['img_size']**2 * 3 * 4 / 1024**3
    print(f"   ğŸ”® é¢„ä¼°GPUå†…å­˜: ~{estimated_memory:.1f} GB")
    
    # ä¿å­˜é…ç½®
    config_file = os.path.join(args.output_dir, 'extreme_config.json')
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': timestamp,
            'config': config,
            'command': ' '.join(cmd),
            'args': vars(args)
        }, f, indent=2, ensure_ascii=False)
    
    # ç¡®è®¤å¯åŠ¨
    response = input(f"\nğŸ”¥ å‡†å¤‡å¯åŠ¨æé™æ€§èƒ½è®­ç»ƒï¼ç»§ç»­ï¼Ÿ(y/N): ").strip().lower()
    if response not in ['y', 'yes']:
        print("âŒ è®­ç»ƒå·²å–æ¶ˆ")
        return 0
    
    print(f"\nğŸš€ å¯åŠ¨æé™è®­ç»ƒ...")
    print(f"ğŸ“Š å®æ—¶æ€§èƒ½ç›‘æ§å·²å¯ç”¨")
    print("-" * 80)
    
    # å¯åŠ¨æ€§èƒ½ç›‘æ§
    monitor_extreme_performance(log_file)
    
    # è¿è¡Œè®­ç»ƒ
    try:
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        
        with open(log_file, 'w', encoding='utf-8') as f:
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                universal_newlines=True,
                bufsize=1
            )
            
            for line in process.stdout:
                print(line, end='')
                f.write(line)
                f.flush()
            
            process.wait()
            return_code = process.returncode
        
        print(f"\n" + "ğŸ”¥" * 40)
        if return_code == 0:
            print("ğŸ‰ æé™è®­ç»ƒæˆåŠŸå®Œæˆï¼")
        else:
            print(f"âŒ è®­ç»ƒå¤±è´¥ï¼Œè¿”å›ç : {return_code}")
        
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
        print(f"ğŸ“ è®­ç»ƒæ—¥å¿—: {log_file}")
        print(f"ğŸ“Š æ€§èƒ½æ—¥å¿—: {log_file.replace('.log', '_extreme_perf.log')}")
        print("ğŸ”¥" * 40)
        
        return return_code
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ‰§è¡Œå‡ºé”™: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 